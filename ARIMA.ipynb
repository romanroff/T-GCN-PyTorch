{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5925,
     "status": "ok",
     "timestamp": 1723127296785,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "OiLGFNvLlWDu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import numpy.linalg as la\n",
    "import math\n",
    "from sklearn.svm import SVR\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1723127296786,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "UbZLFg8xlY5I"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    data1 = np.mat(data)\n",
    "    train_size = int(time_len * rate)\n",
    "    train_data = data1[0:train_size]\n",
    "    test_data = data1[train_size:time_len]\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len):\n",
    "        a = train_data[i: i + seq_len + pre_len]\n",
    "        trainX.append(a[0 : seq_len])\n",
    "        trainY.append(a[seq_len : seq_len + pre_len])\n",
    "    for i in range(len(test_data) - seq_len -pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0 : seq_len])\n",
    "        testY.append(b[seq_len : seq_len + pre_len])\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1723127296786,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "-5zYtdNElbux"
   },
   "outputs": [],
   "source": [
    "def evaluation(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    F_norm = la.norm(a-b)/la.norm(a)\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a - b))/np.var(a)\n",
    "    return rmse, mae, 1-F_norm, r2, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1723127297391,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "hH9fJepFlhy5"
   },
   "outputs": [],
   "source": [
    "path = r'data/los_speed.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "time_len = data.shape[0]\n",
    "num_nodes = data.shape[1]\n",
    "train_rate = 0.8\n",
    "seq_len = 12\n",
    "pre_len = 3\n",
    "trainX,trainY,testX,testY = preprocess_data(data, time_len, train_rate, seq_len, pre_len)\n",
    "method = 'SVR' ####HA or SVR or ARIMA or HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1723127308012,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "VKaMMn55ZACj",
    "outputId": "282e7365-793a-4fdb-e2a0-b251e35b0288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 207)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uN6AcuIYpaO0"
   },
   "outputs": [],
   "source": [
    "testY[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PrVf6oElxfE"
   },
   "outputs": [],
   "source": [
    "if method == 'SVR':\n",
    "    total_rmse, total_mae, total_acc, result = [], [],[],[]\n",
    "    for i in range(num_nodes):\n",
    "        data1 = np.mat(data)\n",
    "        a = data1[:,i]\n",
    "        a_X, a_Y, t_X, t_Y = preprocess_data(a, time_len, train_rate, seq_len, pre_len)\n",
    "        a_X = np.array(a_X)\n",
    "        a_X = np.reshape(a_X,[-1, seq_len])\n",
    "        a_Y = np.array(a_Y)\n",
    "        a_Y = np.reshape(a_Y,[-1, pre_len])\n",
    "        a_Y = np.mean(a_Y, axis=1)\n",
    "        t_X = np.array(t_X)\n",
    "        t_X = np.reshape(t_X,[-1, seq_len])\n",
    "        t_Y = np.array(t_Y)\n",
    "        t_Y = np.reshape(t_Y,[-1, pre_len])\n",
    "\n",
    "        svr_model=SVR(kernel='linear')\n",
    "        svr_model.fit(a_X, a_Y)\n",
    "        pre = svr_model.predict(t_X)\n",
    "        pre = np.array(np.transpose(np.mat(pre)))\n",
    "        pre = pre.repeat(pre_len ,axis=1)\n",
    "        result.append(pre)\n",
    "    result1 = np.array(result)\n",
    "    result1 = np.reshape(result1, [num_nodes,-1])\n",
    "    result1 = np.transpose(result1)\n",
    "    testY1 = np.array(testY)\n",
    "\n",
    "\n",
    "    testY1 = np.reshape(testY1, [-1,num_nodes])\n",
    "    total = np.mat(total_acc)\n",
    "    total[total<0] = 0\n",
    "    rmse1, mae1, acc1,r2,var = evaluation(testY1, result1)\n",
    "    print('SVR_rmse:%r'%rmse1,\n",
    "          'SVR_mae:%r'%mae1,\n",
    "          'SVR_acc:%r'%acc1,\n",
    "          'SVR_r2:%r'%r2,\n",
    "          'SVR_var:%r'%var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1722594223852,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "1OeFt7T8l1qp",
    "outputId": "4db2cbf0-325b-4818-e12e-482d7c81e956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HA_rmse:7.306713710045223 HA_mae:3.878159422422229 HA_acc:0.875611356849716 HA_r2:0.7224883262310877 HA_var:0.7225082534726233\n"
     ]
    }
   ],
   "source": [
    "if method == 'HA':\n",
    "    result = []\n",
    "    for i in range(len(testX)):\n",
    "        a = np.array(testX[i])\n",
    "        tempResult = []\n",
    "\n",
    "        a1 = np.mean(a, axis=0)\n",
    "        tempResult.append(a1)\n",
    "        a = a[1:]\n",
    "        a = np.append(a, [a1], axis=0)\n",
    "        a1 = np.mean(a, axis=0)\n",
    "        tempResult.append(a1)\n",
    "        a = a[1:]\n",
    "        a = np.append(a, [a1], axis=0)\n",
    "        a1 = np.mean(a, axis=0)\n",
    "        tempResult.append(a1)\n",
    "\n",
    "        result.append(tempResult)\n",
    "    result1 = np.array(result)\n",
    "    result1 = np.reshape(result1, [-1,num_nodes])\n",
    "    testY1 = np.array(testY)\n",
    "    testY1 = np.reshape(testY1, [-1,num_nodes])\n",
    "    rmse, mae, accuracy,r2,var = evaluation(testY1, result1)\n",
    "    print('HA_rmse:%r'%rmse,\n",
    "          'HA_mae:%r'%mae,\n",
    "          'HA_acc:%r'%accuracy,\n",
    "          'HA_r2:%r'%r2,\n",
    "          'HA_var:%r'%var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68854,
     "status": "ok",
     "timestamp": 1722594411598,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "8m5iNNQHl5O7",
    "outputId": "427ec00b-c560-46e3-9a46-e020142c0a3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima_rmse:10.081121025557541 arima_mae:7.703074244770337 arima_acc:0.8271754871173042 arima_r2:-0.021484271356060482 arima_var:0.001553890549108091\n"
     ]
    }
   ],
   "source": [
    "if method == 'ARIMA':\n",
    "    rng = pd.date_range('1/3/2012', periods=2016, freq='15min')\n",
    "    a1 = pd.DatetimeIndex(rng)\n",
    "    data.index = a1\n",
    "    num = data.shape[1]\n",
    "    rmse,mae,acc,r2,var,pred,ori = [],[],[],[],[],[],[]\n",
    "    for i in range(156):\n",
    "        ts = data.iloc[:,i]\n",
    "        ts_log=np.log(ts)\n",
    "        ts_log=np.array(ts_log,dtype=np.float64)\n",
    "        where_are_inf = np.isinf(ts_log)\n",
    "        ts_log[where_are_inf] = 0\n",
    "        ts_log = pd.Series(ts_log)\n",
    "        ts_log.index = a1\n",
    "        model = ARIMA(ts_log,order=[1,0,0])\n",
    "        properModel = model.fit()\n",
    "        predict_ts = properModel.predict(4, dynamic=True)\n",
    "        log_recover = np.exp(predict_ts)\n",
    "        ts = ts[log_recover.index]\n",
    "        er_rmse,er_mae,er_acc,r2_score,var_score = evaluation(ts,log_recover)\n",
    "        rmse.append(er_rmse)\n",
    "        mae.append(er_mae)\n",
    "        acc.append(er_acc)\n",
    "        r2.append(r2_score)\n",
    "        var.append(var_score)\n",
    "    acc1 = np.mat(acc)\n",
    "    acc1[acc1 < 0] = 0\n",
    "    print('arima_rmse:%r'%(np.mean(rmse)),\n",
    "          'arima_mae:%r'%(np.mean(mae)),\n",
    "          'arima_acc:%r'%(np.mean(acc1)),\n",
    "          'arima_r2:%r'%(np.mean(r2)),\n",
    "          'arima_var:%r'%(np.mean(var)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM/oiwao0p1L/w/FMZOlYue",
   "mount_file_id": "1tRKEZS1VCIkHAY5lOjN-FQROgkF_3mCu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
