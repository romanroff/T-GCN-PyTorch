{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVp0qeJL_nSm"
   },
   "source": [
    "# Traffic Forecasting with Pytorch Geometric Temporal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaEHCakD_s7q"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7048,
     "status": "ok",
     "timestamp": 1723808505215,
     "user": {
      "displayName": "Alika Sarbassova",
      "userId": "14859410274144410487"
     },
     "user_tz": -300
    },
    "id": "svWjrrJxjp8B",
    "outputId": "52f0bc4f-9d88-415c-91ce-079cc9db5832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import clear_output\n",
    "pt_version = torch.__version__\n",
    "print(pt_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "824V69yXsSub"
   },
   "source": [
    "This took some time for me, so be patient :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dkh77B06vAQL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from ..signal import StaticGraphTemporalSignal\n",
    "\n",
    "\n",
    "class METRLADatasetLoader(object):\n",
    "    \"\"\"A traffic forecasting dataset based on Los Angeles\n",
    "    Metropolitan traffic conditions. The dataset contains traffic\n",
    "    readings collected from 207 loop detectors on highways in Los Angeles\n",
    "    County in aggregated 5 minute intervals for 4 months between March 2012\n",
    "    to June 2012.\n",
    "\n",
    "    For further details on the version of the sensor network and\n",
    "    discretization see: `\"Diffusion Convolutional Recurrent Neural Network:\n",
    "    Data-Driven Traffic Forecasting\" <https://arxiv.org/abs/1707.01926>`_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, raw_data_dir=os.path.join(os.getcwd(), \"data\")):\n",
    "        super(METRLADatasetLoader, self).__init__()\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self._read_web_data()\n",
    "\n",
    "    def _download_url(self, url, save_path):  # pragma: no cover\n",
    "        with urllib.request.urlopen(url) as dl_file:\n",
    "            with open(save_path, \"wb\") as out_file:\n",
    "                out_file.write(dl_file.read())\n",
    "\n",
    "    def _read_web_data(self):\n",
    "        url = \"https://graphmining.ai/temporal_datasets/METR-LA.zip\"\n",
    "\n",
    "        # Check if zip file is in data folder from working directory, otherwise download\n",
    "        if not os.path.isfile(\n",
    "            os.path.join(self.raw_data_dir, \"METR-LA.zip\")\n",
    "        ):  # pragma: no cover\n",
    "            if not os.path.exists(self.raw_data_dir):\n",
    "                os.makedirs(self.raw_data_dir)\n",
    "            self._download_url(url, os.path.join(self.raw_data_dir, \"METR-LA.zip\"))\n",
    "\n",
    "        if not os.path.isfile(\n",
    "            os.path.join(self.raw_data_dir, \"adj_mat.npy\")\n",
    "        ) or not os.path.isfile(\n",
    "            os.path.join(self.raw_data_dir, \"node_values.npy\")\n",
    "        ):  # pragma: no cover\n",
    "            with zipfile.ZipFile(\n",
    "                os.path.join(self.raw_data_dir, \"METR-LA.zip\"), \"r\"\n",
    "            ) as zip_fh:\n",
    "                zip_fh.extractall(self.raw_data_dir)\n",
    "\n",
    "        A = np.load(os.path.join(self.raw_data_dir, \"adj_mat.npy\"))\n",
    "        X = np.load(os.path.join(self.raw_data_dir, \"node_values.npy\")).transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "        X = X.astype(np.float32)\n",
    "\n",
    "        # Normalise as in DCRNN paper (via Z-Score Method)\n",
    "        means = np.mean(X, axis=(0, 2))\n",
    "        X = X - means.reshape(1, -1, 1)\n",
    "        stds = np.std(X, axis=(0, 2))\n",
    "        X = X / stds.reshape(1, -1, 1)\n",
    "\n",
    "        self.A = torch.from_numpy(A)\n",
    "        self.X = torch.from_numpy(X)\n",
    "\n",
    "    def _get_edges_and_weights(self):\n",
    "        edge_indices, values = dense_to_sparse(self.A)\n",
    "        edge_indices = edge_indices.numpy()\n",
    "        values = values.numpy()\n",
    "        self.edges = edge_indices\n",
    "        self.edge_weights = values\n",
    "\n",
    "    def _generate_task(self, num_timesteps_in: int = 12, num_timesteps_out: int = 12):\n",
    "        \"\"\"Uses the node features of the graph and generates a feature/target\n",
    "        relationship of the shape\n",
    "        (num_nodes, num_node_features, num_timesteps_in) -> (num_nodes, num_timesteps_out)\n",
    "        predicting the average traffic speed using num_timesteps_in to predict the\n",
    "        traffic conditions in the next num_timesteps_out\n",
    "\n",
    "        Args:\n",
    "            num_timesteps_in (int): number of timesteps the sequence model sees\n",
    "            num_timesteps_out (int): number of timesteps the sequence model has to predict\n",
    "        \"\"\"\n",
    "        indices = [\n",
    "            (i, i + (num_timesteps_in + num_timesteps_out))\n",
    "            for i in range(self.X.shape[2] - (num_timesteps_in + num_timesteps_out) + 1)\n",
    "        ]\n",
    "\n",
    "        # Generate observations\n",
    "        features, target = [], []\n",
    "        for i, j in indices:\n",
    "            features.append((self.X[:, :, i : i + num_timesteps_in]).numpy())\n",
    "            target.append((self.X[:, 0, i + num_timesteps_in : j]).numpy())\n",
    "\n",
    "        self.features = features\n",
    "        self.targets = target\n",
    "\n",
    "    def get_dataset(\n",
    "        self, num_timesteps_in: int = 12, num_timesteps_out: int = 12\n",
    "    ) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Returns data iterator for METR-LA dataset as an instance of the\n",
    "        static graph temporal signal class.\n",
    "\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)* - The METR-LA traffic\n",
    "                forecasting dataset.\n",
    "        \"\"\"\n",
    "        self._get_edges_and_weights()\n",
    "        self._generate_task(num_timesteps_in, num_timesteps_out)\n",
    "        dataset = StaticGraphTemporalSignal(\n",
    "            self.edges, self.edge_weights, self.features, self.targets\n",
    "        )\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2nTO8PH_vlf"
   },
   "source": [
    "## Dataset\n",
    "- Traffic forecasting dataset based on Los Angeles Metropolitan traffic\n",
    "- 207 loop detectors on highways\n",
    "- March 2012 - June 2012\n",
    "- From the paper: Diffusion Convolutional Recurrent Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOc-jbFckFHn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "\n",
    "loader = METRLADatasetLoader()\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "\n",
    "print(\"Dataset type:  \", dataset)\n",
    "print(\"Number of samples / sequences: \",  len(set(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2zO_CjYBQSt"
   },
   "source": [
    "#### Data Sample\n",
    "- 207 nodes\n",
    "- 2 features per node (speed, time)\n",
    "- 12 timesteps per bucket (12 x 5 min = 60 min)\n",
    "- Labels for 12 future timesteps (normalized speed) --> node regression\n",
    "- Edge_attr is build based on the distances between sensors + threshold\n",
    "- Further details: https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/dataset/metr_la.html#METRLADatasetLoader\n",
    "- Raw data: https://graphmining.ai/temporal_datasets/METR-LA.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClWnMrz0Anjr"
   },
   "outputs": [],
   "source": [
    "# Show first sample\n",
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL3fnTZyQIQz"
   },
   "outputs": [],
   "source": [
    "# Important: It is not always like that!\n",
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "d = ChickenpoxDatasetLoader().get_dataset(lags=4)\n",
    "next(iter(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df8yjwxoA69S"
   },
   "source": [
    "You can always have a look at the source-code to see how a dataset is constructed. Chickenpox would be a classical \"predict-next-timestep\" dataset (the label is one step later than the features).  \n",
    "METR-LA would be a sequence-to-sequence prediction dataset that predicts further into the future than just the next timestep. You can also see, that the features are used as label as well.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# >>> From the ChickenpoxDatasetLoader <<<\n",
    "self.features = [\n",
    "            stacked_target[i : i + self.lags, :].T\n",
    "            for i in range(stacked_target.shape[0] - self.lags)\n",
    "        ]\n",
    "self.targets = [\n",
    "            stacked_target[i + self.lags, :].T  \n",
    "            for i in range(stacked_target.shape[0] - self.lags)\n",
    "        ]\n",
    "\n",
    "# >>> From METRLADatasetLoader <<<\n",
    "indices = [\n",
    "            (i, i + (num_timesteps_in + num_timesteps_out))\n",
    "            for i in range(self.X.shape[2] - (num_timesteps_in + num_timesteps_out) + 1)\n",
    "        ]\n",
    "for i, j in indices:\n",
    "            features.append((self.X[:, :, i : i + num_timesteps_in]).numpy())\n",
    "            target.append((self.X[:, 0, i + num_timesteps_in : j]).numpy())\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrkqXPxFwIx"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Visualize traffic over time\n",
    "sensor_number = 1\n",
    "hours = 24\n",
    "sensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\n",
    "sns.lineplot(data=sensor_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZqDAqQdBS8Q"
   },
   "source": [
    "#### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMn2LXERsyVK"
   },
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "print(\"Number of train buckets: \", len(set(train_dataset)))\n",
    "print(\"Number of test buckets: \", len(set(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1puzm8U_xpY"
   },
   "source": [
    "## Model\n",
    "\n",
    "Which model to choose depends on which time-series task you work on.\n",
    "\n",
    "- A3TGCN is an extension of TGCN that uses attention\n",
    "- The spatial aggregation uses GCN, the temporal aggregation a GRU\n",
    "- We can pass in periods to get an embedding for several timesteps\n",
    "- This embedding can be used to predict several steps into the future = output dimension\n",
    "- We could also do this in a loop and feed it again into the model (would be autoregressive)\n",
    "- There is only one block here. Other layers also allow stacking???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQB8MPV0sU4K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
    "\n",
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods):\n",
    "        super(TemporalGNN, self).__init__()\n",
    "        # Attention Temporal Graph Convolutional Cell\n",
    "        self.tgnn = A3TGCN(in_channels=node_features,\n",
    "                           out_channels=32,\n",
    "                           periods=periods)\n",
    "        # Equals single-shot prediction\n",
    "        self.linear = torch.nn.Linear(32, periods)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x = Node features for T time steps\n",
    "        edge_index = Graph edge indices\n",
    "        \"\"\"\n",
    "        h = self.tgnn(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "TemporalGNN(node_features=2, periods=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDbNmvO2_znb"
   },
   "source": [
    "## Training\n",
    "\n",
    "- Training on GPU didn't bring much speed-up\n",
    "- I ran into RAM issues, why I only train on a smaller subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kOvaOrps2oe"
   },
   "outputs": [],
   "source": [
    "# GPU support\n",
    "device = torch.device('cpu') # cuda\n",
    "subset = 2000\n",
    "\n",
    "# Create model and optimizers\n",
    "model = TemporalGNN(node_features=2, periods=12).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "print(\"Running training...\")\n",
    "for epoch in range(10):\n",
    "    loss = 0\n",
    "    step = 0\n",
    "    for snapshot in train_dataset:\n",
    "        snapshot = snapshot.to(device)\n",
    "        # Get model predictions\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index)\n",
    "        # Mean squared error\n",
    "        loss = loss + torch.mean((y_hat-snapshot.y)**2)\n",
    "        step += 1\n",
    "        if step > subset:\n",
    "          break\n",
    "\n",
    "    loss = loss / (step + 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X18pWbNsPSjb"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "- Lets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\n",
    "- The model always gets one hour and needs to predict the next hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNERp-_xs27y"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loss = 0\n",
    "step = 0\n",
    "horizon = 288\n",
    "\n",
    "# Store for analysis\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for snapshot in test_dataset:\n",
    "    snapshot = snapshot.to(device)\n",
    "    # Get predictions\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index)\n",
    "    # Mean squared error\n",
    "    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n",
    "    # Store for analysis below\n",
    "    labels.append(snapshot.y)\n",
    "    predictions.append(y_hat)\n",
    "    step += 1\n",
    "    if step > horizon:\n",
    "          break\n",
    "\n",
    "loss = loss / (step+1)\n",
    "loss = loss.item()\n",
    "print(\"Test MSE: {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIVZyX1b_IPA"
   },
   "source": [
    "### Visualization\n",
    "\n",
    "- The further away the point in time is, the worse the predictions get\n",
    "- Predictions shape: [num_data_points, num_sensors, num_timesteps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5AJPBdRMb4b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sensor = 123\n",
    "timestep = 11\n",
    "preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in predictions])\n",
    "labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\n",
    "print(\"Data points:,\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08wwv2qUR7z9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.lineplot(data=preds, label=\"pred\")\n",
    "sns.lineplot(data=labs, label=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3GC5nmwSde0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
